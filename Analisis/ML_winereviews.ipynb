{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.svm import SVC, SVR, LinearSVR\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Wine_reviews_climate_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65838 entries, 0 to 65837\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      65838 non-null  int64  \n",
      " 1   country         65838 non-null  object \n",
      " 2   description     65838 non-null  object \n",
      " 3   points          65838 non-null  int64  \n",
      " 4   price           60311 non-null  float64\n",
      " 5   taster_name     65838 non-null  object \n",
      " 6   variety         65838 non-null  object \n",
      " 7   winery          65838 non-null  object \n",
      " 8   Year            65838 non-null  int64  \n",
      " 9   region          65838 non-null  object \n",
      " 10  Latitude        65838 non-null  float64\n",
      " 11  Longitude       65838 non-null  float64\n",
      " 12  Lat_x           65838 non-null  float64\n",
      " 13  Long_x          65838 non-null  float64\n",
      " 14  temp_anual      65838 non-null  float64\n",
      " 15  temp_max_anual  65838 non-null  float64\n",
      " 16  temp_min_anual  65838 non-null  float64\n",
      " 17  pre_anual       65838 non-null  float64\n",
      " 18  etp_anual       65838 non-null  int64  \n",
      "dtypes: float64(9), int64(4), object(6)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "country              0\n",
       "description          0\n",
       "points               0\n",
       "price             5527\n",
       "taster_name          0\n",
       "variety              0\n",
       "winery               0\n",
       "Year                 0\n",
       "region               0\n",
       "Latitude             0\n",
       "Longitude            0\n",
       "Lat_x                0\n",
       "Long_x               0\n",
       "temp_anual           0\n",
       "temp_max_anual       0\n",
       "temp_min_anual       0\n",
       "pre_anual            0\n",
       "etp_anual            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "country           0\n",
       "description       0\n",
       "points            0\n",
       "price             0\n",
       "taster_name       0\n",
       "variety           0\n",
       "winery            0\n",
       "Year              0\n",
       "region            0\n",
       "Latitude          0\n",
       "Longitude         0\n",
       "Lat_x             0\n",
       "Long_x            0\n",
       "temp_anual        0\n",
       "temp_max_anual    0\n",
       "temp_min_anual    0\n",
       "pre_anual         0\n",
       "etp_anual         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deleteing rows with price = 0\n",
    "df.dropna(subset = ['price'], inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lat_x</th>\n",
       "      <th>Long_x</th>\n",
       "      <th>temp_anual</th>\n",
       "      <th>temp_max_anual</th>\n",
       "      <th>temp_min_anual</th>\n",
       "      <th>pre_anual</th>\n",
       "      <th>etp_anual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.25</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>13.10</td>\n",
       "      <td>19.70</td>\n",
       "      <td>6.57</td>\n",
       "      <td>298.7</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.25</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>13.10</td>\n",
       "      <td>19.70</td>\n",
       "      <td>6.57</td>\n",
       "      <td>298.7</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.25</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>13.10</td>\n",
       "      <td>19.70</td>\n",
       "      <td>6.57</td>\n",
       "      <td>298.7</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>91</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.25</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>13.10</td>\n",
       "      <td>19.70</td>\n",
       "      <td>6.57</td>\n",
       "      <td>298.7</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>87</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>2011</td>\n",
       "      <td>41.25</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>13.10</td>\n",
       "      <td>19.70</td>\n",
       "      <td>6.57</td>\n",
       "      <td>298.7</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65833</th>\n",
       "      <td>France</td>\n",
       "      <td>86</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Lauren Buzzeo</td>\n",
       "      <td>2009</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>-35.25</td>\n",
       "      <td>26.38</td>\n",
       "      <td>30.47</td>\n",
       "      <td>22.32</td>\n",
       "      <td>1531.9</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65834</th>\n",
       "      <td>Israel</td>\n",
       "      <td>84</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Lauren Buzzeo</td>\n",
       "      <td>2010</td>\n",
       "      <td>30.75</td>\n",
       "      <td>34.75</td>\n",
       "      <td>21.45</td>\n",
       "      <td>27.60</td>\n",
       "      <td>15.35</td>\n",
       "      <td>81.8</td>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65835</th>\n",
       "      <td>Italy</td>\n",
       "      <td>86</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>2012</td>\n",
       "      <td>40.25</td>\n",
       "      <td>18.25</td>\n",
       "      <td>17.46</td>\n",
       "      <td>21.31</td>\n",
       "      <td>13.65</td>\n",
       "      <td>719.4</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65836</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>90</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Jeff Jenssen</td>\n",
       "      <td>2012</td>\n",
       "      <td>46.75</td>\n",
       "      <td>6.75</td>\n",
       "      <td>9.15</td>\n",
       "      <td>13.46</td>\n",
       "      <td>4.87</td>\n",
       "      <td>1382.5</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65837</th>\n",
       "      <td>Italy</td>\n",
       "      <td>87</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>2012</td>\n",
       "      <td>40.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.09</td>\n",
       "      <td>18.80</td>\n",
       "      <td>11.40</td>\n",
       "      <td>269.6</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60311 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  points  price    taster_name  Year  Lat_x  Long_x  \\\n",
       "0         Portugal      87   15.0     Roger Voss  2011  41.25   -5.25   \n",
       "2         Portugal      87   15.0     Roger Voss  2011  41.25   -5.25   \n",
       "3         Portugal      87   17.0     Roger Voss  2011  41.25   -5.25   \n",
       "4         Portugal      91   12.0     Roger Voss  2011  41.25   -5.25   \n",
       "5         Portugal      87    8.0     Roger Voss  2011  41.25   -5.25   \n",
       "...            ...     ...    ...            ...   ...    ...     ...   \n",
       "65833       France      86   10.0  Lauren Buzzeo  2009  -5.75  -35.25   \n",
       "65834       Israel      84   12.0  Lauren Buzzeo  2010  30.75   34.75   \n",
       "65835        Italy      86   15.0  Kerin O’Keefe  2012  40.25   18.25   \n",
       "65836  Switzerland      90   21.0   Jeff Jenssen  2012  46.75    6.75   \n",
       "65837        Italy      87   25.0  Kerin O’Keefe  2012  40.25   15.25   \n",
       "\n",
       "       temp_anual  temp_max_anual  temp_min_anual  pre_anual  etp_anual  \n",
       "0           13.10           19.70            6.57      298.7       1206  \n",
       "2           13.10           19.70            6.57      298.7       1206  \n",
       "3           13.10           19.70            6.57      298.7       1206  \n",
       "4           13.10           19.70            6.57      298.7       1206  \n",
       "5           13.10           19.70            6.57      298.7       1206  \n",
       "...           ...             ...             ...        ...        ...  \n",
       "65833       26.38           30.47           22.32     1531.9       1332  \n",
       "65834       21.45           27.60           15.35       81.8       1779  \n",
       "65835       17.46           21.31           13.65      719.4       1176  \n",
       "65836        9.15           13.46            4.87     1382.5        696  \n",
       "65837       15.09           18.80           11.40      269.6       1077  \n",
       "\n",
       "[60311 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['description', 'variety', 'winery', 'Latitude', 'Longitude', 'region', 'Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['country', 'taster_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60311 entries, 0 to 65837\n",
      "Data columns (total 70 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   points                          60311 non-null  int64  \n",
      " 1   price                           60311 non-null  float64\n",
      " 2   Year                            60311 non-null  int64  \n",
      " 3   Lat_x                           60311 non-null  float64\n",
      " 4   Long_x                          60311 non-null  float64\n",
      " 5   temp_anual                      60311 non-null  float64\n",
      " 6   temp_max_anual                  60311 non-null  float64\n",
      " 7   temp_min_anual                  60311 non-null  float64\n",
      " 8   pre_anual                       60311 non-null  float64\n",
      " 9   etp_anual                       60311 non-null  int64  \n",
      " 10  country_Argentina               60311 non-null  uint8  \n",
      " 11  country_Australia               60311 non-null  uint8  \n",
      " 12  country_Austria                 60311 non-null  uint8  \n",
      " 13  country_Bosnia and Herzegovina  60311 non-null  uint8  \n",
      " 14  country_Brazil                  60311 non-null  uint8  \n",
      " 15  country_Bulgaria                60311 non-null  uint8  \n",
      " 16  country_Canada                  60311 non-null  uint8  \n",
      " 17  country_Chile                   60311 non-null  uint8  \n",
      " 18  country_China                   60311 non-null  uint8  \n",
      " 19  country_Croatia                 60311 non-null  uint8  \n",
      " 20  country_Cyprus                  60311 non-null  uint8  \n",
      " 21  country_Czech Republic          60311 non-null  uint8  \n",
      " 22  country_England                 60311 non-null  uint8  \n",
      " 23  country_France                  60311 non-null  uint8  \n",
      " 24  country_Georgia                 60311 non-null  uint8  \n",
      " 25  country_Germany                 60311 non-null  uint8  \n",
      " 26  country_Greece                  60311 non-null  uint8  \n",
      " 27  country_Hungary                 60311 non-null  uint8  \n",
      " 28  country_India                   60311 non-null  uint8  \n",
      " 29  country_Israel                  60311 non-null  uint8  \n",
      " 30  country_Italy                   60311 non-null  uint8  \n",
      " 31  country_Lebanon                 60311 non-null  uint8  \n",
      " 32  country_Macedonia               60311 non-null  uint8  \n",
      " 33  country_Mexico                  60311 non-null  uint8  \n",
      " 34  country_Moldova                 60311 non-null  uint8  \n",
      " 35  country_Morocco                 60311 non-null  uint8  \n",
      " 36  country_New Zealand             60311 non-null  uint8  \n",
      " 37  country_Peru                    60311 non-null  uint8  \n",
      " 38  country_Portugal                60311 non-null  uint8  \n",
      " 39  country_Romania                 60311 non-null  uint8  \n",
      " 40  country_Serbia                  60311 non-null  uint8  \n",
      " 41  country_Slovakia                60311 non-null  uint8  \n",
      " 42  country_Slovenia                60311 non-null  uint8  \n",
      " 43  country_South Africa            60311 non-null  uint8  \n",
      " 44  country_Spain                   60311 non-null  uint8  \n",
      " 45  country_Switzerland             60311 non-null  uint8  \n",
      " 46  country_Turkey                  60311 non-null  uint8  \n",
      " 47  country_US                      60311 non-null  uint8  \n",
      " 48  country_Ukraine                 60311 non-null  uint8  \n",
      " 49  country_Uruguay                 60311 non-null  uint8  \n",
      " 50  taster_name_Alexander Peartree  60311 non-null  uint8  \n",
      " 51  taster_name_Anna Lee C. Iijima  60311 non-null  uint8  \n",
      " 52  taster_name_Anne Krebiehl MW    60311 non-null  uint8  \n",
      " 53  taster_name_Anonimo             60311 non-null  uint8  \n",
      " 54  taster_name_Carrie Dykes        60311 non-null  uint8  \n",
      " 55  taster_name_Christina Pickard   60311 non-null  uint8  \n",
      " 56  taster_name_Fiona Adams         60311 non-null  uint8  \n",
      " 57  taster_name_Jeff Jenssen        60311 non-null  uint8  \n",
      " 58  taster_name_Jim Gordon          60311 non-null  uint8  \n",
      " 59  taster_name_Joe Czerwinski      60311 non-null  uint8  \n",
      " 60  taster_name_Kerin O’Keefe       60311 non-null  uint8  \n",
      " 61  taster_name_Lauren Buzzeo       60311 non-null  uint8  \n",
      " 62  taster_name_Matt Kettmann       60311 non-null  uint8  \n",
      " 63  taster_name_Michael Schachner   60311 non-null  uint8  \n",
      " 64  taster_name_Mike DeSimone       60311 non-null  uint8  \n",
      " 65  taster_name_Paul Gregutt        60311 non-null  uint8  \n",
      " 66  taster_name_Roger Voss          60311 non-null  uint8  \n",
      " 67  taster_name_Sean P. Sullivan    60311 non-null  uint8  \n",
      " 68  taster_name_Susan Kostrzewa     60311 non-null  uint8  \n",
      " 69  taster_name_Virginie Boone      60311 non-null  uint8  \n",
      "dtypes: float64(7), int64(3), uint8(60)\n",
      "memory usage: 8.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we separate our info, the X will be all the columns except the output variable, then the output variable, the test size 20% and the random state to have always the same output\n",
    "# is like X, X_test, y, y_test = train_test_split(variables_X, variable_Y, test_size, random_state)\n",
    "X, X_test, y, y_test = train_test_split(data.drop(columns='points'), data.points, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('poly',\n",
       "                                              PolynomialFeatures(include_bias=False)),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'poly__degree': [1, 2],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BEE6D57B50>})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'poly__degree' : [1, 2]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poly__degree': 2, 'ridge__alpha': 197.54222546581198}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39228159892449266"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3927682448982456"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9591211227318752"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.960287126928887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [10, 11, 12, 13, 14, 15],\n",
       "                         'min_samples_leaf': [47, 48, 49, 50, 51, 52, 53]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Now we try a Tree Regressor\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "param_grid = {'max_depth' : [10, 11, 12, 13, 14, 15], 'min_samples_leaf' : [47, 48, 49, 50, 51, 52, 53]}\n",
    "\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "tree_CV = GridSearchCV(tree, param_grid=param_grid)\n",
    "#Now we train the model\n",
    "tree_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Parameters are : {'max_depth': 13, 'min_samples_leaf': 51}\n",
      "The best X,y score is:  0.4835437428790962\n",
      "The best X,y test score is:  0.4450094937785186\n",
      "The MAE X,y is:  1.7918503363274374\n",
      "The MAE test X,y is:  1.8561782882863547\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Parameters are :\", tree_CV.best_params_)\n",
    "print(\"The best X,y score is: \", tree_CV.score(X, y))\n",
    "print(\"The best X,y test score is: \", tree_CV.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(tree_CV.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(tree_CV.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'pca__n_components': [10, 20, 30, 40,\n",
       "                                                              60],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BEEA3CEDC0>})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'pca__n_components' : [10, 20, 30, 40, 60]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 60, 'ridge__alpha': 188.55799358714341}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2536082450702626"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2896477824621121"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.164337738443674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1592246410936866"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'pca__n_components': [60, 62, 64, 66],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BEEA3D63D0>})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'pca__n_components' : [60, 62, 64, 66]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 66, 'ridge__alpha': 194.2962006983842}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25517836902010804"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2916292335498263"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_CV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1614147266411035"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1547789889944764"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(ridge_CV.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('poly',\n",
       "                                              PolynomialFeatures(include_bias=False)),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'pca__n_components': [30, 40, 50, 60],\n",
       "                                        'poly__degree': [1, 2],\n",
       "                                        'ridge__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BEEA452D60>})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "ridge_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('pca', PCA()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'poly__degree': [1,2], 'pca__n_components' : [30, 40, 50, 60]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "ridge_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Parameters are : {'pca__n_components': 60, 'poly__degree': 1, 'ridge__alpha': 156.09475234800144}\n",
      "The best X,y score is:  0.2536095123951819\n",
      "The best X,y test score is:  0.28969740451170156\n",
      "The MAE X,y is:  2.1642099520211384\n",
      "The MAE test X,y is:  2.1590942686141044\n"
     ]
    }
   ],
   "source": [
    "print(\"The best Parameters are :\", ridge_CV.best_params_)\n",
    "print(\"The best X,y score is: \", ridge_CV.score(X, y))\n",
    "print(\"The best X,y test score is: \", ridge_CV.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(ridge_CV.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(ridge_CV.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 397 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('linear', LinearRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "linear_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "#dists = {'ridge__alpha' : uniform(loc=0, scale=200), 'poly__degree': [1,2], 'pca__n_components' : [30, 40, 50, 60]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "#Now we train the model\n",
    "linear_pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  0.2552441568778654\n",
      "The best X,y test score is:  0.29199847481116614\n",
      "The MAE X,y is:  2.1605649713768558\n",
      "The MAE test X,y is:  2.153679593342132\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", linear_pipe.score(X, y))\n",
    "print(\"The best X,y test score is: \", linear_pipe.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(linear_pipe.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(linear_pipe.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccoronad\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm',\n",
       "                 LinearSVR(C=1000, epsilon=1, max_iter=10000,\n",
       "                           random_state=42))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', LinearSVR(C=1000, epsilon=1, max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  -0.03210921663527344\n",
      "The best X,y test score is:  0.11399980735559823\n",
      "The MAE X,y is:  2.3061862699723172\n",
      "The MAE test X,y is:  2.2814496808986777\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", svm.score(X, y))\n",
    "print(\"The best X,y test score is: \", svm.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(svm.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(svm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm', SVR(C=1000, epsilon=0.5))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVR(kernel='rbf', C=1000, epsilon=0.5))\n",
    "])\n",
    "\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  0.4911043450098398\n",
      "The best X,y test score is:  0.4640080289215628\n",
      "The MAE X,y is:  1.7530581206334592\n",
      "The MAE test X,y is:  1.7998869002845972\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", svm.score(X, y))\n",
    "print(\"The best X,y test score is: \", svm.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(svm.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(svm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 257 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()), ('gnb', GaussianNB())])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "gnb_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('gnb', GaussianNB())\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "#dists = {'gnb__alpha' : uniform(loc=0, scale=200)}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "#ridge_CV = RandomizedSearchCV(ridge_pipe, param_distributions=dists, n_iter=30, cv=5)\n",
    "#Now we train the model\n",
    "gnb_pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best X,y score is:  0.007046924224838335\n",
      "The best X,y test score is:  0.0073779325209317745\n",
      "The MAE X,y is:  9.984123694246394\n",
      "The MAE test X,y is:  9.946116223161734\n"
     ]
    }
   ],
   "source": [
    "print(\"The best X,y score is: \", gnb_pipe.score(X, y))\n",
    "print(\"The best X,y test score is: \", gnb_pipe.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(gnb_pipe.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(gnb_pipe.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#We create the Pipeline. First step, Normalize data, include the Polynomimal \n",
    "#(include bias false to remove from the Polynomial for X[0]=1) and then use the Ridge method\n",
    "svr_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVR(C=1000, epsilon=0.5))\n",
    "])\n",
    "\n",
    "#In a dictionary, Step name _ _ and then parameter name, and then : with the type to do\n",
    "dists = {'svm__c' : [1000, 3000, 5000], 'svm__epsilon': [0.001, 0.1, 1]}\n",
    "#Cross Validation (CV uses the n parts (1/5) for cv=5, n_inter is the number of models, )\n",
    "svr_CV = RandomizedSearchCV(svr_pipe, param_distributions=dists, n_iter=3, cv=5)\n",
    "#Now we train the model\n",
    "svr_CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best Parameters are :\", svr_CV.best_params_)\n",
    "print(\"The best X,y score is: \", svr_CV.score(X, y))\n",
    "print(\"The best X,y test score is: \", svr_CV.score(X_test, y_test))\n",
    "print(\"The MAE X,y is: \", mean_absolute_error(svr_CV.predict(X), y))\n",
    "print(\"The MAE test X,y is: \", mean_absolute_error(svr_CV.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
